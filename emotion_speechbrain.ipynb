{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df6a2cd9",
   "metadata": {},
   "source": [
    "# Emotion Detection using `speechbrain/emotion-recognition-wav2vec2-IEMOCAP` (Fixed Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install speechbrain==0.5.15 torchaudio librosa soundfile numpy noisereduce -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dccb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "audio_file = next(iter(uploaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013faf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "\n",
    "def preprocess_sb(input_path, output_path=\"sb_cleaned.wav\", target_sr=16000):\n",
    "    y, sr = librosa.load(input_path, sr=None, mono=True)\n",
    "    y_denoised = nr.reduce_noise(y=y, sr=sr)\n",
    "    y_denoised = librosa.util.normalize(y_denoised)\n",
    "    y_resampled = librosa.resample(y_denoised, orig_sr=sr, target_sr=target_sr)\n",
    "    sf.write(output_path, y_resampled, target_sr)\n",
    "    return output_path\n",
    "\n",
    "cleaned_audio = preprocess_sb(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import EmotionRecognition\n",
    "\n",
    "model = EmotionRecognition.from_hparams(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\")\n",
    "output = model.classify_file(cleaned_audio)\n",
    "\n",
    "print(\"Predicted Emotion:\", output['emotion'])\n",
    "print(\"Scores by class:\")\n",
    "for emotion, score in output['scores'].items():\n",
    "    print(f\"  {emotion}: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
